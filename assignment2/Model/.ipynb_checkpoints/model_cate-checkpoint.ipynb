{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "certified-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "local-oxford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>...</th>\n",
       "      <th>comp6_rate_percent_diff</th>\n",
       "      <th>comp7_rate</th>\n",
       "      <th>comp7_inv</th>\n",
       "      <th>comp7_rate_percent_diff</th>\n",
       "      <th>comp8_rate</th>\n",
       "      <th>comp8_inv</th>\n",
       "      <th>comp8_rate_percent_diff</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>gross_bookings_usd</th>\n",
       "      <th>booking_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>251866.000000</td>\n",
       "      <td>252988.000000</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>4.950983e+06</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>96174.000000</td>\n",
       "      <td>315348.000000</td>\n",
       "      <td>356422.000000</td>\n",
       "      <td>138515.000000</td>\n",
       "      <td>1.916654e+06</td>\n",
       "      <td>1.987503e+06</td>\n",
       "      <td>614730.000000</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>138390.000000</td>\n",
       "      <td>4.958347e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.663666e+05</td>\n",
       "      <td>9.953133e+00</td>\n",
       "      <td>1.753405e+02</td>\n",
       "      <td>3.374334</td>\n",
       "      <td>176.022659</td>\n",
       "      <td>1.739739e+02</td>\n",
       "      <td>7.007918e+04</td>\n",
       "      <td>3.180525e+00</td>\n",
       "      <td>3.777777e+00</td>\n",
       "      <td>6.346994e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>17.250473</td>\n",
       "      <td>0.145969</td>\n",
       "      <td>0.083202</td>\n",
       "      <td>19.433267</td>\n",
       "      <td>-6.089936e-02</td>\n",
       "      <td>9.962752e-03</td>\n",
       "      <td>22.430384</td>\n",
       "      <td>4.474858e-02</td>\n",
       "      <td>386.283316</td>\n",
       "      <td>2.791051e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.611223e+04</td>\n",
       "      <td>7.646890e+00</td>\n",
       "      <td>6.591625e+01</td>\n",
       "      <td>0.692519</td>\n",
       "      <td>107.254493</td>\n",
       "      <td>6.834525e+01</td>\n",
       "      <td>4.060992e+04</td>\n",
       "      <td>1.051024e+00</td>\n",
       "      <td>1.050329e+00</td>\n",
       "      <td>4.815144e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>31.160313</td>\n",
       "      <td>0.578202</td>\n",
       "      <td>0.316722</td>\n",
       "      <td>54.370221</td>\n",
       "      <td>4.691723e-01</td>\n",
       "      <td>2.029142e-01</td>\n",
       "      <td>895.965854</td>\n",
       "      <td>2.067514e-01</td>\n",
       "      <td>821.190577</td>\n",
       "      <td>1.647165e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.293600e+04</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>109.810000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>3.501000e+04</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.665070e+05</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>2.190000e+02</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>152.240000</td>\n",
       "      <td>2.190000e+02</td>\n",
       "      <td>6.963800e+04</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>218.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.497240e+05</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>2.190000e+02</td>\n",
       "      <td>3.930000</td>\n",
       "      <td>213.490000</td>\n",
       "      <td>2.190000e+02</td>\n",
       "      <td>1.051680e+05</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.500000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>429.790000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.327850e+05</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>2.310000e+02</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1958.700000</td>\n",
       "      <td>2.300000e+02</td>\n",
       "      <td>1.408210e+05</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1620.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9900.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>149400.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>159292.380000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            srch_id       site_id  visitor_location_country_id  \\\n",
       "count  4.958347e+06  4.958347e+06                 4.958347e+06   \n",
       "mean   1.663666e+05  9.953133e+00                 1.753405e+02   \n",
       "std    9.611223e+04  7.646890e+00                 6.591625e+01   \n",
       "min    1.000000e+00  1.000000e+00                 1.000000e+00   \n",
       "25%    8.293600e+04  5.000000e+00                 1.000000e+02   \n",
       "50%    1.665070e+05  5.000000e+00                 2.190000e+02   \n",
       "75%    2.497240e+05  1.400000e+01                 2.190000e+02   \n",
       "max    3.327850e+05  3.400000e+01                 2.310000e+02   \n",
       "\n",
       "       visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  \\\n",
       "count            251866.000000         252988.000000     4.958347e+06   \n",
       "mean                  3.374334            176.022659     1.739739e+02   \n",
       "std                   0.692519            107.254493     6.834525e+01   \n",
       "min                   1.410000              0.000000     1.000000e+00   \n",
       "25%                   2.920000            109.810000     1.000000e+02   \n",
       "50%                   3.450000            152.240000     2.190000e+02   \n",
       "75%                   3.930000            213.490000     2.190000e+02   \n",
       "max                   5.000000           1958.700000     2.300000e+02   \n",
       "\n",
       "            prop_id  prop_starrating  prop_review_score  prop_brand_bool  ...  \\\n",
       "count  4.958347e+06     4.958347e+06       4.950983e+06     4.958347e+06  ...   \n",
       "mean   7.007918e+04     3.180525e+00       3.777777e+00     6.346994e-01  ...   \n",
       "std    4.060992e+04     1.051024e+00       1.050329e+00     4.815144e-01  ...   \n",
       "min    1.000000e+00     0.000000e+00       0.000000e+00     0.000000e+00  ...   \n",
       "25%    3.501000e+04     3.000000e+00       3.500000e+00     0.000000e+00  ...   \n",
       "50%    6.963800e+04     3.000000e+00       4.000000e+00     1.000000e+00  ...   \n",
       "75%    1.051680e+05     4.000000e+00       4.500000e+00     1.000000e+00  ...   \n",
       "max    1.408210e+05     5.000000e+00       5.000000e+00     1.000000e+00  ...   \n",
       "\n",
       "       comp6_rate_percent_diff     comp7_rate      comp7_inv  \\\n",
       "count             96174.000000  315348.000000  356422.000000   \n",
       "mean                 17.250473       0.145969       0.083202   \n",
       "std                  31.160313       0.578202       0.316722   \n",
       "min                   2.000000      -1.000000      -1.000000   \n",
       "25%                   6.000000       0.000000       0.000000   \n",
       "50%                  11.000000       0.000000       0.000000   \n",
       "75%                  18.000000       1.000000       0.000000   \n",
       "max                1620.000000       1.000000       1.000000   \n",
       "\n",
       "       comp7_rate_percent_diff    comp8_rate     comp8_inv  \\\n",
       "count            138515.000000  1.916654e+06  1.987503e+06   \n",
       "mean                 19.433267 -6.089936e-02  9.962752e-03   \n",
       "std                  54.370221  4.691723e-01  2.029142e-01   \n",
       "min                   2.000000 -1.000000e+00 -1.000000e+00   \n",
       "25%                   7.000000  0.000000e+00  0.000000e+00   \n",
       "50%                  12.000000  0.000000e+00  0.000000e+00   \n",
       "75%                  20.000000  0.000000e+00  0.000000e+00   \n",
       "max                9900.000000  1.000000e+00  1.000000e+00   \n",
       "\n",
       "       comp8_rate_percent_diff    click_bool  gross_bookings_usd  booking_bool  \n",
       "count            614730.000000  4.958347e+06       138390.000000  4.958347e+06  \n",
       "mean                 22.430384  4.474858e-02          386.283316  2.791051e-02  \n",
       "std                 895.965854  2.067514e-01          821.190577  1.647165e-01  \n",
       "min                   2.000000  0.000000e+00            0.000000  0.000000e+00  \n",
       "25%                   7.000000  0.000000e+00          124.000000  0.000000e+00  \n",
       "50%                  11.000000  0.000000e+00          218.400000  0.000000e+00  \n",
       "75%                  17.000000  0.000000e+00          429.790000  0.000000e+00  \n",
       "max              149400.000000  1.000000e+00       159292.380000  1.000000e+00  \n",
       "\n",
       "[8 rows x 53 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/training_set_VU_DM.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-penetration",
   "metadata": {},
   "source": [
    "### Feature eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "earned-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    \"\"\"\n",
    "    reads the file in pandas df and converts the date_time column to datetime type\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    return df\n",
    "\n",
    "def sample_on_srch_id(df, frac = 0.1):\n",
    "    \"\"\"\n",
    "    samples the dataframe based on the fraction of srach_id\n",
    "    \"\"\"\n",
    "    # get unique srch_ids\n",
    "    srch_ids = np.unique(df.srch_id)\n",
    "    # calculate how many ids to return\n",
    "    chosen_k = int(len(srch_ids) * frac)\n",
    "    # sample ids\n",
    "    chosen_ids = random.sample(list(srch_ids), k = chosen_k)\n",
    "    # filter the df to only have sampled ids\n",
    "    return df[df['srch_id'].isin(chosen_ids)]\n",
    "\n",
    "### Feature Engineering --------------------------\n",
    "\n",
    "## missing data ----------------------------------\n",
    "\n",
    "def remove_missing_values(df):\n",
    "    \"\"\"\n",
    "    removes columns with more than 50 percent missing data\n",
    "    \"\"\"\n",
    "    missing_values = df.isna().mean().round(4) * 100\n",
    "    missing_values = pd.DataFrame(missing_values).reset_index()\n",
    "    missing_values.columns = [\"column\", \"missing\"]\n",
    "    # filter where there are missing values\n",
    "    missing_values.query(\"missing > 50\", inplace=True)  # remove columns with more than 50 % of missing values\n",
    "    missing_values.sort_values(\"missing\", inplace=True)\n",
    "    #print(missing_values)\n",
    "    df.drop(missing_values.column, axis=1, inplace=True)\n",
    "\n",
    "def replace_missing_values(df):\n",
    "    \"\"\"\n",
    "    imputes missing values with -1\n",
    "    \"\"\"\n",
    "    df.fillna(value=-1, inplace=True) \n",
    "\n",
    "## new features ----------------------------------\n",
    "\n",
    "def extract_time(df):\n",
    "    \"\"\" \n",
    "    month, week, day of the week and hour of search\n",
    "    \"\"\"\n",
    "    df_datetime = pd.DatetimeIndex(df.date_time)\n",
    "    df[\"month\"] = df_datetime.month\n",
    "    df[\"week\"] = df_datetime.week\n",
    "    df[\"day\"] = df_datetime.dayofweek + 1\n",
    "    df[\"hour\"] = df_datetime.hour\n",
    "    df.drop(\"date_time\", inplace=True, axis=1)\n",
    "\n",
    "def new_historical_price(df):\n",
    "    \"\"\"\n",
    "    'unlogs' prop_log_historical_price column\n",
    "    \"\"\"\n",
    "    df[\"prop_historical_price\"] = (np.e ** df.prop_log_historical_price).replace(1.0, 0)\n",
    "    df.drop(\"prop_log_historical_price\", axis=1, inplace=True)\n",
    "\n",
    "def add_price_position(df, rank_type = \"dense\"):\n",
    "    \"\"\"\n",
    "    adds hotel price position (\"price_position\") inside \"srch_id\" column\n",
    "    \"\"\"\n",
    "    ranks = df.groupby('srch_id')['price_usd'].rank(ascending=True, method = rank_type)\n",
    "    df[\"price_position\"] = ranks\n",
    "\n",
    "\n",
    "def average_numerical_features(df, group_by = [\"prop_id\"], columns = [\"prop_starrating\", \"prop_review_score\", \"prop_location_score1\", \"prop_location_score2\"]):\n",
    "    \"\"\"\n",
    "    adds mean, median and standard deviation per prop_id (default) \n",
    "    for columns that are related to property (default)\n",
    "    \"\"\"\n",
    "    # caulcate means and rename columns\n",
    "    means = df.groupby(group_by)[columns].mean().reset_index()\n",
    "    means.columns = [means.columns[0]] + [x + \"_mean\" for x in means.columns[1:]]\n",
    "    # caulcate median and rename columns\n",
    "    medians = df.groupby(group_by)[columns].median().reset_index()\n",
    "    medians.columns = [medians.columns[0]] + [x + \"_median\" for x in medians.columns[1:]]\n",
    "    # caulcate means and rename columns\n",
    "    stds = df.groupby(group_by)[columns].std().reset_index()\n",
    "    stds.columns = [stds.columns[0]] + [x + \"_std\" for x in stds.columns[1:]]\n",
    "    ## attach aggregated data to the df\n",
    "    df = pd.merge(df, means, on=group_by)\n",
    "    df = pd.merge(df, medians, on=group_by)\n",
    "    df = pd.merge(df, stds, on=group_by)\n",
    "    return df\n",
    "\n",
    "def add_historical_booking_click(df):\n",
    "    \"\"\"\n",
    "    creates a column with the percentage of the prop_id booked/clicked rate overall\n",
    "    \"\"\"\n",
    "    # there are more prop_id in the test data than in train. \n",
    "    # Maybe we could still use this but would need to impute\n",
    "    # with the most common value (or something else)\n",
    "    \n",
    "    historical = df.groupby(\"prop_id\")[[\"click_bool\", \"booking_bool\"]].mean().reset_index()\n",
    "    historical.columns = [historical.columns[0]] + [x + \"_rate\" for x in historical.columns[1:]]\n",
    "    df = pd.merge(df, historical, on=\"prop_id\")\n",
    "    return df\n",
    "    \n",
    "    \n",
    "## other ----------------------------------\n",
    "\n",
    "def remove_positions(df, positions = [5, 11, 17, 23]):\n",
    "    \"\"\"\n",
    "    removes hotels with specified positions \n",
    "    (based on the fact that hotels in those positions were not as booked)\n",
    "    \"\"\"\n",
    "    df = df[df[\"position\"].isin(positions) == False]\n",
    "    \n",
    "### Feature engineering function -----------\n",
    "\n",
    "def feature_engineering(df):\n",
    "    extract_time(df)\n",
    "    remove_missing_values(df)\n",
    "    replace_missing_values(df)\n",
    "    new_historical_price(df)\n",
    "    add_price_position(df)\n",
    "    average_numerical_features(df)\n",
    "\n",
    "def add_score(df):\n",
    "    \"\"\"\n",
    "    adds 'score' column to the df: 5 for booked, 1 for clicked\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    for book, click in zip(df.booking_bool, df.click_bool):\n",
    "        if book == 1:\n",
    "            score.append(5)\n",
    "            continue\n",
    "        if click == 1:\n",
    "            score.append(1)\n",
    "            continue\n",
    "        else:\n",
    "            score.append(0)\n",
    "    df[\"score\"] = score\n",
    "\n",
    "def create_df_queries_freq(df):\n",
    "    df_queries = pd.DataFrame()\n",
    "    df_queries = pd.crosstab(index=df['srch_id'], columns='count', colnames=['srch_id'])\n",
    "    df_queries.sort_values(\"srch_id\")\n",
    "    df_queries.to_csv(\"../df_queries.csv\")\n",
    "    return pd.read_csv(\"../df_queries.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-liability",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "derived-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import DMatrix\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "third-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = read_file(\"../data/training_set_VU_DM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "direct-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_true.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "maritime-diversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-1e25d0782193>:53: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  df[\"week\"] = df_datetime.week\n"
     ]
    }
   ],
   "source": [
    "feature_engineering(df)\n",
    "add_score(df)\n",
    "del df[\"prop_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "motivated-array",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>prop_location_score1</th>\n",
       "      <th>prop_location_score2</th>\n",
       "      <th>position</th>\n",
       "      <th>...</th>\n",
       "      <th>random_bool</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>booking_bool</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>prop_historical_price</th>\n",
       "      <th>price_position</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>141.174964</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>152.933013</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>137.002613</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>80.640419</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>219</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>138.379512</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id  site_id  visitor_location_country_id  prop_country_id  \\\n",
       "0        1       12                          187              219   \n",
       "1        1       12                          187              219   \n",
       "2        1       12                          187              219   \n",
       "3        1       12                          187              219   \n",
       "4        1       12                          187              219   \n",
       "\n",
       "   prop_starrating  prop_review_score  prop_brand_bool  prop_location_score1  \\\n",
       "0                3                3.5                1                  2.83   \n",
       "1                4                4.0                1                  2.20   \n",
       "2                3                4.5                1                  2.20   \n",
       "3                2                4.0                1                  2.83   \n",
       "4                4                3.5                1                  2.64   \n",
       "\n",
       "   prop_location_score2  position  ...  random_bool  click_bool  booking_bool  \\\n",
       "0                0.0438        27  ...            1           0             0   \n",
       "1                0.0149        26  ...            1           0             0   \n",
       "2                0.0245        21  ...            1           0             0   \n",
       "3                0.0125        34  ...            1           0             0   \n",
       "4                0.1241         4  ...            1           0             0   \n",
       "\n",
       "   month  week  day  hour  prop_historical_price  price_position  score  \n",
       "0      4    14    4     8             141.174964             3.0      0  \n",
       "1      4    14    4     8             152.933013            14.0      0  \n",
       "2      4    14    4     8             137.002613            15.0      0  \n",
       "3      4    14    4     8              80.640419            22.0      0  \n",
       "4      4    14    4     8             138.379512            11.0      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fundamental-actress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srch_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count\n",
       "srch_id       \n",
       "1           28\n",
       "4           32\n",
       "6            5\n",
       "8           21\n",
       "11          33"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_queries = create_df_queries_freq(df)\n",
    "df_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "amino-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(test_size=.20, n_splits=1, random_state = 7).split(df, groups=df['srch_id'])\n",
    "\n",
    "X_train_inds, X_test_inds = next(gss)\n",
    "\n",
    "train_data= df.iloc[X_train_inds]\n",
    "X_train = train_data.loc[:, ~train_data.columns.isin(['srch_id','score'])]\n",
    "y_train = train_data.loc[:, train_data.columns.isin(['score'])]\n",
    "\n",
    "test_data= df.iloc[X_test_inds]\n",
    "\n",
    "#We need to keep the id for later predictions\n",
    "X_test = test_data.loc[:, ~test_data.columns.isin(['score'])]\n",
    "y_test = test_data.loc[:, test_data.columns.isin(['score'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "absolute-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = train_data.groupby('srch_id').size().to_frame('size')['size'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "infrared-offer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRanker(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "          colsample_bynode=1, colsample_bytree=0.9, eta=0.05, gamma=0,\n",
       "          gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "          learning_rate=0.1, max_delta_step=0, max_depth=6, min_child_weight=1,\n",
       "          missing=nan, monotone_constraints='()', n_estimators=110, n_jobs=8,\n",
       "          num_parallel_tree=1, random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "          scale_pos_weight=None, subsample=0.75, tree_method='hist',\n",
       "          validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRanker(  \n",
    "    tree_method='hist',\n",
    "    booster='gbtree',\n",
    "    objective='rank:pairwise',\n",
    "    random_state=42, \n",
    "    learning_rate=0.1,\n",
    "    colsample_bytree=0.9, \n",
    "    eta=0.05, \n",
    "    max_depth=6, \n",
    "    n_estimators=110, \n",
    "    subsample=0.75 \n",
    "    )\n",
    "\n",
    "model.fit(X_train, y_train, group=groups, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "flexible-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, df):\n",
    "    return model.predict(df.loc[:, ~df.columns.isin(['srch_id'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bizarre-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "circular-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (test_data.groupby('srch_id')\n",
    "               .apply(lambda x: predict(model, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "correct-vampire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "srch_id\n",
       "12        [-4.9389257, -5.081862, -5.0494037, -4.9986615...\n",
       "17        [-4.9081817, -4.6608906, -4.824098, -4.893706,...\n",
       "25        [-4.9267898, -5.184382, -4.9740186, -5.1030445...\n",
       "28        [-4.923067, -5.1873136, -5.10615, 6.422535, -5...\n",
       "52        [-5.2281966, -5.212973, -5.0933366, -5.185809,...\n",
       "                                ...                        \n",
       "332726    [-5.130711, -5.126967, -5.290471, -5.0915856, ...\n",
       "332736    [-5.1268325, -5.230109, -5.0945168, -5.2254725...\n",
       "332749    [-4.912473, -4.8937078, -4.794091, -4.885281, ...\n",
       "332768    [-5.125128, -5.0417323, -5.0906773, -5.204948,...\n",
       "332784    [-5.211203, -5.131001, -5.0514736, -5.229484, ...\n",
       "Length: 39959, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-corner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
